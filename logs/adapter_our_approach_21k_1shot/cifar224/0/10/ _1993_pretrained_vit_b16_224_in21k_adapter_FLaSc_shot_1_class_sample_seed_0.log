2025-05-19 22:17:10,949 [trainer.py] => Starting new run
2025-05-19 22:17:10,950 [trainer.py] => ID: 1
2025-05-19 22:17:10,950 [trainer.py] => dataset: cifar224
2025-05-19 22:17:10,950 [trainer.py] => shuffle: True
2025-05-19 22:17:10,950 [trainer.py] => init_cls: 10
2025-05-19 22:17:10,950 [trainer.py] => increment: 10
2025-05-19 22:17:10,950 [trainer.py] => model_name: adapter
2025-05-19 22:17:10,950 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k_adapter
2025-05-19 22:17:10,950 [trainer.py] => device: [device(type='cuda', index=0)]
2025-05-19 22:17:10,950 [trainer.py] => seed: 1993
2025-05-19 22:17:10,950 [trainer.py] => batch_size: 50
2025-05-19 22:17:10,950 [trainer.py] => tuned_epoch: 20
2025-05-19 22:17:10,950 [trainer.py] => body_lr: 0.01
2025-05-19 22:17:10,950 [trainer.py] => head_lr: 0.01
2025-05-19 22:17:10,950 [trainer.py] => weight_decay: 0.0005
2025-05-19 22:17:10,951 [trainer.py] => min_lr: 0.0
2025-05-19 22:17:10,951 [trainer.py] => use_RP: True
2025-05-19 22:17:10,951 [trainer.py] => M: 10000
2025-05-19 22:17:10,951 [trainer.py] => use_input_norm: False
2025-05-19 22:17:10,951 [trainer.py] => meta: True
2025-05-19 22:17:10,951 [trainer.py] => exp_details: FLaSc
2025-05-19 22:17:10,951 [trainer.py] => do_not_save: False
2025-05-19 22:17:10,951 [trainer.py] => seed_path: ./subsets/cifar100/shot1_seed0.txt
2025-05-19 22:17:10,951 [trainer.py] => class_samples_seed: 0
2025-05-19 22:17:10,951 [trainer.py] => shot: 1
2025-05-19 22:17:12,549 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-05-19 22:17:12,908 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-05-19 22:17:52,751 [data_manager.py] => Class Order: [68,56,78,8,23,84,90,65,74,76,40,89,3,92,55,9,26,80,43,38,58,70,77,1,85,19,17,50,28,53,13,81,45,82,6,59,83,16,15,44,91,41,72,60,79,52,20,10,31,54,37,95,14,71,96,98,97,2,64,66,42,22,35,86,24,34,87,21,99,0,88,27,18,94,11,12,47,25,30,46,62,69,36,61,7,63,75,5,32,4,51,48,73,93,39,67,29,49,57,33]
2025-05-19 22:17:52,772 [trainer.py] => Pre-trained network parameters: 86988288
2025-05-19 22:17:55,191 [FLaSc.py] => Starting CIL Task 1
2025-05-19 22:17:55,191 [FLaSc.py] => Learning on classes 0-9
2025-05-19 22:17:55,196 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:17:55,196 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:17:55,196 [FLaSc.py] => len_test data : 1000
2025-05-19 22:17:55,197 [FLaSc.py] => classes learning unique, count: (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:17:55,271 [FLaSc.py] => 86,995,969 total parameters.
2025-05-19 22:17:55,272 [FLaSc.py] => 1,197,313 training parameters.
2025-05-19 22:17:55,273 [FLaSc.py] => Starting PETL training on first task using adapter method
2025-05-19 22:17:55,273 [FLaSc.py] => Training Started with self -supervised loss......
2025-05-19 22:17:55,277 [FLaSc.py] => Weight scale value mse ...... 1.0
2025-05-19 22:20:01,539 [FLaSc.py] => Task 0, Epoch 20/20 => Loss 0.913, Train_accy 0.00, Test_accy 7.80
2025-05-19 22:20:12,770 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:20:12,770 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:20:13,358 [FLaSc.py] => 87,088,289 total parameters.
2025-05-19 22:20:13,359 [FLaSc.py] => 100,001 training parameters.
2025-05-19 22:20:17,866 [trainer.py] => Group Accuracies after this task: {'00-09': 75.9}
2025-05-19 22:20:17,866 [trainer.py] => Ave Acc curve: [75.9]
2025-05-19 22:20:17,866 [trainer.py] => Ave Inc Acc curve: 75.9
2025-05-19 22:20:17,866 [trainer.py] => Top1 curve: [75.9]
2025-05-19 22:20:17,867 [FLaSc.py] => Starting CIL Task 2
2025-05-19 22:20:17,867 [FLaSc.py] => Learning on classes 10-19
2025-05-19 22:20:17,874 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:20:17,874 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:20:17,874 [FLaSc.py] => len_test data : 2000
2025-05-19 22:20:17,874 [FLaSc.py] => classes learning unique, count: (array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:20:28,932 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:20:28,932 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:20:29,524 [FLaSc.py] => 87,188,289 total parameters.
2025-05-19 22:20:29,525 [FLaSc.py] => 200,001 training parameters.
2025-05-19 22:20:37,712 [trainer.py] => Group Accuracies after this task: {'00-09': 73.2, '10-19': 62.9}
2025-05-19 22:20:37,712 [trainer.py] => Ave Acc curve: [75.9, 68.05]
2025-05-19 22:20:37,712 [trainer.py] => Ave Inc Acc curve: 71.975
2025-05-19 22:20:37,712 [trainer.py] => Top1 curve: [75.9, 68.05]
2025-05-19 22:20:37,713 [FLaSc.py] => Starting CIL Task 3
2025-05-19 22:20:37,713 [FLaSc.py] => Learning on classes 20-29
2025-05-19 22:20:37,720 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:20:37,720 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:20:37,720 [FLaSc.py] => len_test data : 3000
2025-05-19 22:20:37,720 [FLaSc.py] => classes learning unique, count: (array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:20:48,691 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:20:48,691 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:20:49,290 [FLaSc.py] => 87,288,289 total parameters.
2025-05-19 22:20:49,290 [FLaSc.py] => 300,001 training parameters.
2025-05-19 22:21:00,267 [trainer.py] => Group Accuracies after this task: {'00-09': 66.7, '10-19': 59.7, '20-29': 86.9}
2025-05-19 22:21:00,267 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1]
2025-05-19 22:21:00,267 [trainer.py] => Ave Inc Acc curve: 71.68333333333332
2025-05-19 22:21:00,267 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1]
2025-05-19 22:21:00,268 [FLaSc.py] => Starting CIL Task 4
2025-05-19 22:21:00,268 [FLaSc.py] => Learning on classes 30-39
2025-05-19 22:21:00,279 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:21:00,279 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:21:00,279 [FLaSc.py] => len_test data : 4000
2025-05-19 22:21:00,279 [FLaSc.py] => classes learning unique, count: (array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:21:11,296 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:21:11,296 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:21:11,895 [FLaSc.py] => 87,388,289 total parameters.
2025-05-19 22:21:11,895 [FLaSc.py] => 400,001 training parameters.
2025-05-19 22:21:25,682 [trainer.py] => Group Accuracies after this task: {'00-09': 63.6, '10-19': 56.6, '20-29': 81.5, '30-39': 77.7}
2025-05-19 22:21:25,682 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85]
2025-05-19 22:21:25,682 [trainer.py] => Ave Inc Acc curve: 71.225
2025-05-19 22:21:25,682 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85]
2025-05-19 22:21:25,683 [FLaSc.py] => Starting CIL Task 5
2025-05-19 22:21:25,683 [FLaSc.py] => Learning on classes 40-49
2025-05-19 22:21:25,696 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:21:25,696 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:21:25,696 [FLaSc.py] => len_test data : 5000
2025-05-19 22:21:25,696 [FLaSc.py] => classes learning unique, count: (array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:21:36,721 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:21:36,721 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:21:37,322 [FLaSc.py] => 87,488,289 total parameters.
2025-05-19 22:21:37,322 [FLaSc.py] => 500,001 training parameters.
2025-05-19 22:21:53,535 [trainer.py] => Group Accuracies after this task: {'00-09': 62.2, '10-19': 51.9, '20-29': 76.4, '30-39': 71.9, '40-49': 64.2}
2025-05-19 22:21:53,535 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32]
2025-05-19 22:21:53,535 [trainer.py] => Ave Inc Acc curve: 70.044
2025-05-19 22:21:53,535 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32]
2025-05-19 22:21:53,536 [FLaSc.py] => Starting CIL Task 6
2025-05-19 22:21:53,536 [FLaSc.py] => Learning on classes 50-59
2025-05-19 22:21:53,550 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:21:53,550 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:21:53,550 [FLaSc.py] => len_test data : 6000
2025-05-19 22:21:53,550 [FLaSc.py] => classes learning unique, count: (array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:22:04,557 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:22:04,558 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:22:05,158 [FLaSc.py] => 87,588,289 total parameters.
2025-05-19 22:22:05,158 [FLaSc.py] => 600,001 training parameters.
2025-05-19 22:22:24,032 [trainer.py] => Group Accuracies after this task: {'00-09': 60.9, '10-19': 50.8, '20-29': 72.9, '30-39': 71.0, '40-49': 62.4, '50-59': 64.5}
2025-05-19 22:22:24,032 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75]
2025-05-19 22:22:24,032 [trainer.py] => Ave Inc Acc curve: 68.99499999999999
2025-05-19 22:22:24,032 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75]
2025-05-19 22:22:24,033 [FLaSc.py] => Starting CIL Task 7
2025-05-19 22:22:24,033 [FLaSc.py] => Learning on classes 60-69
2025-05-19 22:22:24,051 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:22:24,051 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:22:24,051 [FLaSc.py] => len_test data : 7000
2025-05-19 22:22:24,052 [FLaSc.py] => classes learning unique, count: (array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:22:35,083 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:22:35,083 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:22:35,680 [FLaSc.py] => 87,688,289 total parameters.
2025-05-19 22:22:35,680 [FLaSc.py] => 700,001 training parameters.
2025-05-19 22:22:57,105 [trainer.py] => Group Accuracies after this task: {'00-09': 57.8, '10-19': 49.7, '20-29': 72.7, '30-39': 70.4, '40-49': 62.2, '50-59': 62.6, '60-69': 69.8}
2025-05-19 22:22:57,105 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6]
2025-05-19 22:22:57,105 [trainer.py] => Ave Inc Acc curve: 68.22428571428571
2025-05-19 22:22:57,105 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6]
2025-05-19 22:22:57,106 [FLaSc.py] => Starting CIL Task 8
2025-05-19 22:22:57,106 [FLaSc.py] => Learning on classes 70-79
2025-05-19 22:22:57,124 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:22:57,124 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:22:57,124 [FLaSc.py] => len_test data : 8000
2025-05-19 22:22:57,124 [FLaSc.py] => classes learning unique, count: (array([70, 71, 72, 73, 74, 75, 76, 77, 78, 79]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:23:08,262 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:23:08,262 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:23:08,854 [FLaSc.py] => 87,788,289 total parameters.
2025-05-19 22:23:08,855 [FLaSc.py] => 800,001 training parameters.
2025-05-19 22:23:33,009 [trainer.py] => Group Accuracies after this task: {'00-09': 56.8, '10-19': 49.7, '20-29': 72.6, '30-39': 70.1, '40-49': 60.1, '50-59': 57.5, '60-69': 66.3, '70-79': 46.2}
2025-05-19 22:23:33,009 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91]
2025-05-19 22:23:33,009 [trainer.py] => Ave Inc Acc curve: 67.185
2025-05-19 22:23:33,009 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91]
2025-05-19 22:23:33,010 [FLaSc.py] => Starting CIL Task 9
2025-05-19 22:23:33,010 [FLaSc.py] => Learning on classes 80-89
2025-05-19 22:23:33,029 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:23:33,029 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:23:33,029 [FLaSc.py] => len_test data : 9000
2025-05-19 22:23:33,029 [FLaSc.py] => classes learning unique, count: (array([80, 81, 82, 83, 84, 85, 86, 87, 88, 89]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:23:44,073 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:23:44,073 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:23:44,682 [FLaSc.py] => 87,888,289 total parameters.
2025-05-19 22:23:44,683 [FLaSc.py] => 900,001 training parameters.
2025-05-19 22:24:11,404 [trainer.py] => Group Accuracies after this task: {'00-09': 55.8, '10-19': 48.1, '20-29': 70.9, '30-39': 68.3, '40-49': 59.5, '50-59': 57.3, '60-69': 66.0, '70-79': 46.1, '80-89': 59.6}
2025-05-19 22:24:11,404 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91, 59.07]
2025-05-19 22:24:11,404 [trainer.py] => Ave Inc Acc curve: 66.28333333333335
2025-05-19 22:24:11,404 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91, 59.07]
2025-05-19 22:24:11,405 [FLaSc.py] => Starting CIL Task 10
2025-05-19 22:24:11,405 [FLaSc.py] => Learning on classes 90-99
2025-05-19 22:24:11,426 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:24:11,426 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:24:11,426 [FLaSc.py] => len_test data : 10000
2025-05-19 22:24:11,426 [FLaSc.py] => classes learning unique, count: (array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:24:22,584 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:24:22,585 [FLaSc.py] => Optimal lambda: 100000000.0
2025-05-19 22:24:23,179 [FLaSc.py] => 87,988,289 total parameters.
2025-05-19 22:24:23,180 [FLaSc.py] => 1,000,001 training parameters.
2025-05-19 22:24:52,986 [trainer.py] => Group Accuracies after this task: {'00-09': 55.2, '10-19': 47.1, '20-29': 70.6, '30-39': 67.3, '40-49': 58.6, '50-59': 56.6, '60-69': 65.7, '70-79': 44.6, '80-89': 59.5, '90-99': 64.9}
2025-05-19 22:24:52,987 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91, 59.07, 59.01]
2025-05-19 22:24:52,987 [trainer.py] => Ave Inc Acc curve: 65.55600000000001
2025-05-19 22:24:52,987 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91, 59.07, 59.01]
2025-05-19 22:24:52,987 [trainer.py] => Finishing run
2025-05-19 22:24:52,987 [trainer.py] => 
2025-05-19 22:34:29,626 [trainer.py] => Starting new run
2025-05-19 22:34:29,626 [trainer.py] => ID: 1
2025-05-19 22:34:29,626 [trainer.py] => dataset: cifar224
2025-05-19 22:34:29,626 [trainer.py] => shuffle: True
2025-05-19 22:34:29,626 [trainer.py] => init_cls: 10
2025-05-19 22:34:29,626 [trainer.py] => increment: 10
2025-05-19 22:34:29,626 [trainer.py] => model_name: adapter
2025-05-19 22:34:29,626 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k_adapter
2025-05-19 22:34:29,627 [trainer.py] => device: [device(type='cuda', index=0)]
2025-05-19 22:34:29,627 [trainer.py] => seed: 1993
2025-05-19 22:34:29,627 [trainer.py] => batch_size: 50
2025-05-19 22:34:29,627 [trainer.py] => tuned_epoch: 20
2025-05-19 22:34:29,627 [trainer.py] => body_lr: 0.01
2025-05-19 22:34:29,627 [trainer.py] => head_lr: 0.01
2025-05-19 22:34:29,627 [trainer.py] => weight_decay: 0.0005
2025-05-19 22:34:29,627 [trainer.py] => min_lr: 0.0
2025-05-19 22:34:29,627 [trainer.py] => use_RP: True
2025-05-19 22:34:29,627 [trainer.py] => M: 10000
2025-05-19 22:34:29,627 [trainer.py] => use_input_norm: False
2025-05-19 22:34:29,627 [trainer.py] => meta: True
2025-05-19 22:34:29,627 [trainer.py] => exp_details: FLaSc
2025-05-19 22:34:29,627 [trainer.py] => do_not_save: False
2025-05-19 22:34:29,627 [trainer.py] => seed_path: ./subsets/cifar100/shot1_seed0.txt
2025-05-19 22:34:29,627 [trainer.py] => class_samples_seed: 0
2025-05-19 22:34:29,627 [trainer.py] => shot: 1
2025-05-19 22:34:31,560 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-05-19 22:34:31,887 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-05-19 22:34:32,859 [data_manager.py] => Class Order: [68,56,78,8,23,84,90,65,74,76,40,89,3,92,55,9,26,80,43,38,58,70,77,1,85,19,17,50,28,53,13,81,45,82,6,59,83,16,15,44,91,41,72,60,79,52,20,10,31,54,37,95,14,71,96,98,97,2,64,66,42,22,35,86,24,34,87,21,99,0,88,27,18,94,11,12,47,25,30,46,62,69,36,61,7,63,75,5,32,4,51,48,73,93,39,67,29,49,57,33]
2025-05-19 22:34:32,873 [trainer.py] => Pre-trained network parameters: 86988288
2025-05-19 22:34:34,072 [FLaSc.py] => Starting CIL Task 1
2025-05-19 22:34:34,072 [FLaSc.py] => Learning on classes 0-9
2025-05-19 22:34:34,074 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:34:34,074 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:34:34,074 [FLaSc.py] => len_test data : 1000
2025-05-19 22:34:34,074 [FLaSc.py] => classes learning unique, count: (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:34:34,140 [FLaSc.py] => 86,995,969 total parameters.
2025-05-19 22:34:34,141 [FLaSc.py] => 1,197,313 training parameters.
2025-05-19 22:34:34,142 [FLaSc.py] => Starting PETL training on first task using adapter method
2025-05-19 22:34:34,142 [FLaSc.py] => Training Started with self -supervised loss......
2025-05-19 22:34:34,142 [FLaSc.py] => Weight scale value mse ...... 1.0
2025-05-19 22:36:38,966 [FLaSc.py] => Task 0, Epoch 20/20 => Loss 0.913, Train_accy 0.00, Test_accy 7.80
2025-05-19 22:36:50,290 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:36:50,896 [FLaSc.py] => 87,088,289 total parameters.
2025-05-19 22:36:50,897 [FLaSc.py] => 100,001 training parameters.
2025-05-19 22:36:55,462 [trainer.py] => Group Accuracies after this task: {'00-09': 75.9}
2025-05-19 22:36:55,462 [trainer.py] => Ave Acc curve: [75.9]
2025-05-19 22:36:55,462 [trainer.py] => Ave Inc Acc curve: 75.9
2025-05-19 22:36:55,462 [trainer.py] => Top1 curve: [75.9]
2025-05-19 22:36:55,462 [FLaSc.py] => Starting CIL Task 2
2025-05-19 22:36:55,462 [FLaSc.py] => Learning on classes 10-19
2025-05-19 22:36:55,467 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:36:55,467 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:36:55,467 [FLaSc.py] => len_test data : 2000
2025-05-19 22:36:55,467 [FLaSc.py] => classes learning unique, count: (array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:37:06,481 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:37:07,077 [FLaSc.py] => 87,188,289 total parameters.
2025-05-19 22:37:07,078 [FLaSc.py] => 200,001 training parameters.
2025-05-19 22:37:15,382 [trainer.py] => Group Accuracies after this task: {'00-09': 73.2, '10-19': 62.9}
2025-05-19 22:37:15,382 [trainer.py] => Ave Acc curve: [75.9, 68.05]
2025-05-19 22:37:15,382 [trainer.py] => Ave Inc Acc curve: 71.975
2025-05-19 22:37:15,382 [trainer.py] => Top1 curve: [75.9, 68.05]
2025-05-19 22:37:15,382 [FLaSc.py] => Starting CIL Task 3
2025-05-19 22:37:15,383 [FLaSc.py] => Learning on classes 20-29
2025-05-19 22:37:15,389 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:37:15,389 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:37:15,389 [FLaSc.py] => len_test data : 3000
2025-05-19 22:37:15,389 [FLaSc.py] => classes learning unique, count: (array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:37:26,324 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:37:26,920 [FLaSc.py] => 87,288,289 total parameters.
2025-05-19 22:37:26,921 [FLaSc.py] => 300,001 training parameters.
2025-05-19 22:37:37,878 [trainer.py] => Group Accuracies after this task: {'00-09': 66.7, '10-19': 59.7, '20-29': 86.9}
2025-05-19 22:37:37,878 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1]
2025-05-19 22:37:37,879 [trainer.py] => Ave Inc Acc curve: 71.68333333333332
2025-05-19 22:37:37,879 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1]
2025-05-19 22:37:37,879 [FLaSc.py] => Starting CIL Task 4
2025-05-19 22:37:37,879 [FLaSc.py] => Learning on classes 30-39
2025-05-19 22:37:37,890 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:37:37,890 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:37:37,890 [FLaSc.py] => len_test data : 4000
2025-05-19 22:37:37,890 [FLaSc.py] => classes learning unique, count: (array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:37:49,027 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:37:49,622 [FLaSc.py] => 87,388,289 total parameters.
2025-05-19 22:37:49,623 [FLaSc.py] => 400,001 training parameters.
2025-05-19 22:38:03,346 [trainer.py] => Group Accuracies after this task: {'00-09': 63.6, '10-19': 56.6, '20-29': 81.5, '30-39': 77.7}
2025-05-19 22:38:03,346 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85]
2025-05-19 22:38:03,346 [trainer.py] => Ave Inc Acc curve: 71.225
2025-05-19 22:38:03,346 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85]
2025-05-19 22:38:03,347 [FLaSc.py] => Starting CIL Task 5
2025-05-19 22:38:03,347 [FLaSc.py] => Learning on classes 40-49
2025-05-19 22:38:03,364 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:38:03,364 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:38:03,364 [FLaSc.py] => len_test data : 5000
2025-05-19 22:38:03,364 [FLaSc.py] => classes learning unique, count: (array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:38:14,538 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:38:15,171 [FLaSc.py] => 87,488,289 total parameters.
2025-05-19 22:38:15,172 [FLaSc.py] => 500,001 training parameters.
2025-05-19 22:38:31,350 [trainer.py] => Group Accuracies after this task: {'00-09': 62.2, '10-19': 51.9, '20-29': 76.4, '30-39': 71.9, '40-49': 64.2}
2025-05-19 22:38:31,350 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32]
2025-05-19 22:38:31,350 [trainer.py] => Ave Inc Acc curve: 70.044
2025-05-19 22:38:31,350 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32]
2025-05-19 22:38:31,351 [FLaSc.py] => Starting CIL Task 6
2025-05-19 22:38:31,351 [FLaSc.py] => Learning on classes 50-59
2025-05-19 22:38:31,365 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:38:31,366 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:38:31,366 [FLaSc.py] => len_test data : 6000
2025-05-19 22:38:31,366 [FLaSc.py] => classes learning unique, count: (array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:38:42,434 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:38:43,028 [FLaSc.py] => 87,588,289 total parameters.
2025-05-19 22:38:43,029 [FLaSc.py] => 600,001 training parameters.
2025-05-19 22:39:01,902 [trainer.py] => Group Accuracies after this task: {'00-09': 60.9, '10-19': 50.8, '20-29': 72.9, '30-39': 71.0, '40-49': 62.4, '50-59': 64.5}
2025-05-19 22:39:01,902 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75]
2025-05-19 22:39:01,902 [trainer.py] => Ave Inc Acc curve: 68.99499999999999
2025-05-19 22:39:01,902 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75]
2025-05-19 22:39:01,902 [FLaSc.py] => Starting CIL Task 7
2025-05-19 22:39:01,903 [FLaSc.py] => Learning on classes 60-69
2025-05-19 22:39:01,918 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:39:01,918 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:39:01,918 [FLaSc.py] => len_test data : 7000
2025-05-19 22:39:01,919 [FLaSc.py] => classes learning unique, count: (array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:39:12,973 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:39:13,568 [FLaSc.py] => 87,688,289 total parameters.
2025-05-19 22:39:13,569 [FLaSc.py] => 700,001 training parameters.
2025-05-19 22:39:35,086 [trainer.py] => Group Accuracies after this task: {'00-09': 57.8, '10-19': 49.7, '20-29': 72.7, '30-39': 70.4, '40-49': 62.2, '50-59': 62.6, '60-69': 69.8}
2025-05-19 22:39:35,086 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6]
2025-05-19 22:39:35,086 [trainer.py] => Ave Inc Acc curve: 68.22428571428571
2025-05-19 22:39:35,086 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6]
2025-05-19 22:39:35,087 [FLaSc.py] => Starting CIL Task 8
2025-05-19 22:39:35,087 [FLaSc.py] => Learning on classes 70-79
2025-05-19 22:39:35,104 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:39:35,104 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:39:35,104 [FLaSc.py] => len_test data : 8000
2025-05-19 22:39:35,104 [FLaSc.py] => classes learning unique, count: (array([70, 71, 72, 73, 74, 75, 76, 77, 78, 79]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:39:46,215 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:39:46,813 [FLaSc.py] => 87,788,289 total parameters.
2025-05-19 22:39:46,814 [FLaSc.py] => 800,001 training parameters.
2025-05-19 22:40:10,941 [trainer.py] => Group Accuracies after this task: {'00-09': 56.8, '10-19': 49.7, '20-29': 72.6, '30-39': 70.1, '40-49': 60.1, '50-59': 57.5, '60-69': 66.3, '70-79': 46.2}
2025-05-19 22:40:10,941 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91]
2025-05-19 22:40:10,941 [trainer.py] => Ave Inc Acc curve: 67.185
2025-05-19 22:40:10,941 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91]
2025-05-19 22:40:10,942 [FLaSc.py] => Starting CIL Task 9
2025-05-19 22:40:10,942 [FLaSc.py] => Learning on classes 80-89
2025-05-19 22:40:10,962 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:40:10,962 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:40:10,962 [FLaSc.py] => len_test data : 9000
2025-05-19 22:40:10,962 [FLaSc.py] => classes learning unique, count: (array([80, 81, 82, 83, 84, 85, 86, 87, 88, 89]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:40:22,030 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:40:22,634 [FLaSc.py] => 87,888,289 total parameters.
2025-05-19 22:40:22,634 [FLaSc.py] => 900,001 training parameters.
2025-05-19 22:40:49,440 [trainer.py] => Group Accuracies after this task: {'00-09': 55.8, '10-19': 48.1, '20-29': 70.9, '30-39': 68.3, '40-49': 59.5, '50-59': 57.3, '60-69': 66.0, '70-79': 46.1, '80-89': 59.6}
2025-05-19 22:40:49,440 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91, 59.07]
2025-05-19 22:40:49,440 [trainer.py] => Ave Inc Acc curve: 66.28333333333335
2025-05-19 22:40:49,440 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91, 59.07]
2025-05-19 22:40:49,441 [FLaSc.py] => Starting CIL Task 10
2025-05-19 22:40:49,441 [FLaSc.py] => Learning on classes 90-99
2025-05-19 22:40:49,459 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:40:49,459 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:40:49,459 [FLaSc.py] => len_test data : 10000
2025-05-19 22:40:49,460 [FLaSc.py] => classes learning unique, count: (array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:41:00,700 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:41:01,298 [FLaSc.py] => 87,988,289 total parameters.
2025-05-19 22:41:01,299 [FLaSc.py] => 1,000,001 training parameters.
2025-05-19 22:41:31,215 [trainer.py] => Group Accuracies after this task: {'00-09': 55.2, '10-19': 47.1, '20-29': 70.6, '30-39': 67.3, '40-49': 58.6, '50-59': 56.6, '60-69': 65.7, '70-79': 44.6, '80-89': 59.5, '90-99': 64.9}
2025-05-19 22:41:31,215 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91, 59.07, 59.01]
2025-05-19 22:41:31,215 [trainer.py] => Ave Inc Acc curve: 65.55600000000001
2025-05-19 22:41:31,215 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91, 59.07, 59.01]
2025-05-19 22:41:31,215 [trainer.py] => Finishing run
2025-05-19 22:41:31,215 [trainer.py] => 
2025-05-19 22:51:04,277 [trainer.py] => Starting new run
2025-05-19 22:51:04,278 [trainer.py] => ID: 1
2025-05-19 22:51:04,278 [trainer.py] => dataset: cifar224
2025-05-19 22:51:04,278 [trainer.py] => shuffle: True
2025-05-19 22:51:04,278 [trainer.py] => init_cls: 10
2025-05-19 22:51:04,278 [trainer.py] => increment: 10
2025-05-19 22:51:04,278 [trainer.py] => model_name: adapter
2025-05-19 22:51:04,278 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k_adapter
2025-05-19 22:51:04,278 [trainer.py] => device: [device(type='cuda', index=0)]
2025-05-19 22:51:04,278 [trainer.py] => seed: 1993
2025-05-19 22:51:04,278 [trainer.py] => batch_size: 50
2025-05-19 22:51:04,278 [trainer.py] => tuned_epoch: 20
2025-05-19 22:51:04,278 [trainer.py] => body_lr: 0.01
2025-05-19 22:51:04,278 [trainer.py] => head_lr: 0.01
2025-05-19 22:51:04,278 [trainer.py] => weight_decay: 0.0005
2025-05-19 22:51:04,278 [trainer.py] => min_lr: 0.0
2025-05-19 22:51:04,278 [trainer.py] => use_RP: True
2025-05-19 22:51:04,278 [trainer.py] => M: 10000
2025-05-19 22:51:04,278 [trainer.py] => use_input_norm: False
2025-05-19 22:51:04,278 [trainer.py] => meta: True
2025-05-19 22:51:04,278 [trainer.py] => exp_details: FLaSc
2025-05-19 22:51:04,278 [trainer.py] => do_not_save: False
2025-05-19 22:51:04,278 [trainer.py] => seed_path: ./subsets/cifar100/shot1_seed0.txt
2025-05-19 22:51:04,278 [trainer.py] => class_samples_seed: 0
2025-05-19 22:51:04,278 [trainer.py] => shot: 1
2025-05-19 22:51:05,939 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-05-19 22:51:06,596 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-05-19 22:51:07,571 [data_manager.py] => Class Order: [68,56,78,8,23,84,90,65,74,76,40,89,3,92,55,9,26,80,43,38,58,70,77,1,85,19,17,50,28,53,13,81,45,82,6,59,83,16,15,44,91,41,72,60,79,52,20,10,31,54,37,95,14,71,96,98,97,2,64,66,42,22,35,86,24,34,87,21,99,0,88,27,18,94,11,12,47,25,30,46,62,69,36,61,7,63,75,5,32,4,51,48,73,93,39,67,29,49,57,33]
2025-05-19 22:51:07,585 [trainer.py] => Pre-trained network parameters: 86988288
2025-05-19 22:51:08,512 [FLaSc.py] => Starting CIL Task 1
2025-05-19 22:51:08,513 [FLaSc.py] => Learning on classes 0-9
2025-05-19 22:51:08,515 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:51:08,515 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:51:08,515 [FLaSc.py] => len_test data : 1000
2025-05-19 22:51:08,515 [FLaSc.py] => classes learning unique, count: (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:51:08,574 [FLaSc.py] => 86,995,969 total parameters.
2025-05-19 22:51:08,574 [FLaSc.py] => 1,197,313 training parameters.
2025-05-19 22:51:08,575 [FLaSc.py] => Starting PETL training on first task using adapter method
2025-05-19 22:51:08,575 [FLaSc.py] => Training Started with self -supervised loss......
2025-05-19 22:51:08,575 [FLaSc.py] => Weight scale value mse ...... 1.0
2025-05-19 22:53:14,339 [FLaSc.py] => Task 0, Epoch 20/20 => Loss 0.913, Train_accy 0.00, Test_accy 7.80
2025-05-19 22:53:25,626 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:53:26,228 [FLaSc.py] => 87,088,289 total parameters.
2025-05-19 22:53:26,229 [FLaSc.py] => 100,001 training parameters.
2025-05-19 22:53:30,814 [trainer.py] => Group Accuracies after this task: {'00-09': 75.9}
2025-05-19 22:53:30,814 [trainer.py] => Ave Acc curve: [75.9]
2025-05-19 22:53:30,814 [trainer.py] => Ave Inc Acc curve: 75.9
2025-05-19 22:53:30,814 [trainer.py] => Top1 curve: [75.9]
2025-05-19 22:53:30,815 [FLaSc.py] => Starting CIL Task 2
2025-05-19 22:53:30,815 [FLaSc.py] => Learning on classes 10-19
2025-05-19 22:53:30,819 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:53:30,819 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:53:30,819 [FLaSc.py] => len_test data : 2000
2025-05-19 22:53:30,820 [FLaSc.py] => classes learning unique, count: (array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:53:41,721 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:53:42,321 [FLaSc.py] => 87,188,289 total parameters.
2025-05-19 22:53:42,322 [FLaSc.py] => 200,001 training parameters.
2025-05-19 22:53:50,744 [trainer.py] => Group Accuracies after this task: {'00-09': 73.2, '10-19': 62.9}
2025-05-19 22:53:50,744 [trainer.py] => Ave Acc curve: [75.9, 68.05]
2025-05-19 22:53:50,744 [trainer.py] => Ave Inc Acc curve: 71.975
2025-05-19 22:53:50,745 [trainer.py] => Top1 curve: [75.9, 68.05]
2025-05-19 22:53:50,745 [FLaSc.py] => Starting CIL Task 3
2025-05-19 22:53:50,745 [FLaSc.py] => Learning on classes 20-29
2025-05-19 22:53:50,752 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:53:50,753 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:53:50,753 [FLaSc.py] => len_test data : 3000
2025-05-19 22:53:50,753 [FLaSc.py] => classes learning unique, count: (array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:54:01,710 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:54:02,303 [FLaSc.py] => 87,288,289 total parameters.
2025-05-19 22:54:02,304 [FLaSc.py] => 300,001 training parameters.
2025-05-19 22:54:13,357 [trainer.py] => Group Accuracies after this task: {'00-09': 66.7, '10-19': 59.7, '20-29': 86.9}
2025-05-19 22:54:13,357 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1]
2025-05-19 22:54:13,358 [trainer.py] => Ave Inc Acc curve: 71.68333333333332
2025-05-19 22:54:13,358 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1]
2025-05-19 22:54:13,358 [FLaSc.py] => Starting CIL Task 4
2025-05-19 22:54:13,358 [FLaSc.py] => Learning on classes 30-39
2025-05-19 22:54:13,369 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:54:13,369 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:54:13,369 [FLaSc.py] => len_test data : 4000
2025-05-19 22:54:13,369 [FLaSc.py] => classes learning unique, count: (array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:54:24,393 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:54:24,995 [FLaSc.py] => 87,388,289 total parameters.
2025-05-19 22:54:24,996 [FLaSc.py] => 400,001 training parameters.
2025-05-19 22:54:38,693 [trainer.py] => Group Accuracies after this task: {'00-09': 63.6, '10-19': 56.6, '20-29': 81.5, '30-39': 77.7}
2025-05-19 22:54:38,693 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85]
2025-05-19 22:54:38,693 [trainer.py] => Ave Inc Acc curve: 71.225
2025-05-19 22:54:38,693 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85]
2025-05-19 22:54:38,694 [FLaSc.py] => Starting CIL Task 5
2025-05-19 22:54:38,694 [FLaSc.py] => Learning on classes 40-49
2025-05-19 22:54:38,706 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:54:38,706 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:54:38,706 [FLaSc.py] => len_test data : 5000
2025-05-19 22:54:38,706 [FLaSc.py] => classes learning unique, count: (array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:54:49,834 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:54:50,424 [FLaSc.py] => 87,488,289 total parameters.
2025-05-19 22:54:50,425 [FLaSc.py] => 500,001 training parameters.
2025-05-19 22:55:06,865 [trainer.py] => Group Accuracies after this task: {'00-09': 62.2, '10-19': 51.9, '20-29': 76.4, '30-39': 71.9, '40-49': 64.2}
2025-05-19 22:55:06,865 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32]
2025-05-19 22:55:06,865 [trainer.py] => Ave Inc Acc curve: 70.044
2025-05-19 22:55:06,865 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32]
2025-05-19 22:55:06,866 [FLaSc.py] => Starting CIL Task 6
2025-05-19 22:55:06,866 [FLaSc.py] => Learning on classes 50-59
2025-05-19 22:55:06,880 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:55:06,880 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:55:06,880 [FLaSc.py] => len_test data : 6000
2025-05-19 22:55:06,880 [FLaSc.py] => classes learning unique, count: (array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:55:17,977 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:55:18,571 [FLaSc.py] => 87,588,289 total parameters.
2025-05-19 22:55:18,572 [FLaSc.py] => 600,001 training parameters.
2025-05-19 22:55:37,526 [trainer.py] => Group Accuracies after this task: {'00-09': 60.9, '10-19': 50.8, '20-29': 72.9, '30-39': 71.0, '40-49': 62.4, '50-59': 64.5}
2025-05-19 22:55:37,526 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75]
2025-05-19 22:55:37,526 [trainer.py] => Ave Inc Acc curve: 68.99499999999999
2025-05-19 22:55:37,526 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75]
2025-05-19 22:55:37,527 [FLaSc.py] => Starting CIL Task 7
2025-05-19 22:55:37,527 [FLaSc.py] => Learning on classes 60-69
2025-05-19 22:55:37,543 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:55:37,543 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:55:37,543 [FLaSc.py] => len_test data : 7000
2025-05-19 22:55:37,544 [FLaSc.py] => classes learning unique, count: (array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:55:48,607 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:55:49,203 [FLaSc.py] => 87,688,289 total parameters.
2025-05-19 22:55:49,203 [FLaSc.py] => 700,001 training parameters.
2025-05-19 22:56:10,749 [trainer.py] => Group Accuracies after this task: {'00-09': 57.8, '10-19': 49.7, '20-29': 72.7, '30-39': 70.4, '40-49': 62.2, '50-59': 62.6, '60-69': 69.8}
2025-05-19 22:56:10,749 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6]
2025-05-19 22:56:10,749 [trainer.py] => Ave Inc Acc curve: 68.22428571428571
2025-05-19 22:56:10,750 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6]
2025-05-19 22:56:10,750 [FLaSc.py] => Starting CIL Task 8
2025-05-19 22:56:10,750 [FLaSc.py] => Learning on classes 70-79
2025-05-19 22:56:10,769 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:56:10,769 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:56:10,769 [FLaSc.py] => len_test data : 8000
2025-05-19 22:56:10,769 [FLaSc.py] => classes learning unique, count: (array([70, 71, 72, 73, 74, 75, 76, 77, 78, 79]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:56:21,793 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:56:22,396 [FLaSc.py] => 87,788,289 total parameters.
2025-05-19 22:56:22,397 [FLaSc.py] => 800,001 training parameters.
2025-05-19 22:56:46,695 [trainer.py] => Group Accuracies after this task: {'00-09': 56.8, '10-19': 49.7, '20-29': 72.6, '30-39': 70.1, '40-49': 60.1, '50-59': 57.5, '60-69': 66.3, '70-79': 46.2}
2025-05-19 22:56:46,695 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91]
2025-05-19 22:56:46,695 [trainer.py] => Ave Inc Acc curve: 67.185
2025-05-19 22:56:46,695 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91]
2025-05-19 22:56:46,696 [FLaSc.py] => Starting CIL Task 9
2025-05-19 22:56:46,696 [FLaSc.py] => Learning on classes 80-89
2025-05-19 22:56:46,715 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:56:46,715 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:56:46,715 [FLaSc.py] => len_test data : 9000
2025-05-19 22:56:46,716 [FLaSc.py] => classes learning unique, count: (array([80, 81, 82, 83, 84, 85, 86, 87, 88, 89]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:56:57,834 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:56:58,428 [FLaSc.py] => 87,888,289 total parameters.
2025-05-19 22:56:58,429 [FLaSc.py] => 900,001 training parameters.
2025-05-19 22:57:25,131 [trainer.py] => Group Accuracies after this task: {'00-09': 55.8, '10-19': 48.1, '20-29': 70.9, '30-39': 68.3, '40-49': 59.5, '50-59': 57.3, '60-69': 66.0, '70-79': 46.1, '80-89': 59.6}
2025-05-19 22:57:25,131 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91, 59.07]
2025-05-19 22:57:25,131 [trainer.py] => Ave Inc Acc curve: 66.28333333333335
2025-05-19 22:57:25,131 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91, 59.07]
2025-05-19 22:57:25,132 [FLaSc.py] => Starting CIL Task 10
2025-05-19 22:57:25,132 [FLaSc.py] => Learning on classes 90-99
2025-05-19 22:57:25,154 [FLaSc.py] => len_supervised data : 10
2025-05-19 22:57:25,154 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 22:57:25,154 [FLaSc.py] => len_test data : 10000
2025-05-19 22:57:25,154 [FLaSc.py] => classes learning unique, count: (array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 22:57:36,322 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 22:57:36,919 [FLaSc.py] => 87,988,289 total parameters.
2025-05-19 22:57:36,920 [FLaSc.py] => 1,000,001 training parameters.
2025-05-19 22:58:06,387 [trainer.py] => Group Accuracies after this task: {'00-09': 55.2, '10-19': 47.1, '20-29': 70.6, '30-39': 67.3, '40-49': 58.6, '50-59': 56.6, '60-69': 65.7, '70-79': 44.6, '80-89': 59.5, '90-99': 64.9}
2025-05-19 22:58:06,387 [trainer.py] => Ave Acc curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91, 59.07, 59.01]
2025-05-19 22:58:06,387 [trainer.py] => Ave Inc Acc curve: 65.55600000000001
2025-05-19 22:58:06,387 [trainer.py] => Top1 curve: [75.9, 68.05, 71.1, 69.85, 65.32, 63.75, 63.6, 59.91, 59.07, 59.01]
2025-05-19 22:58:06,387 [trainer.py] => Finishing run
2025-05-19 22:58:06,387 [trainer.py] => 
