2025-05-19 23:19:23,548 [trainer.py] => Starting new run
2025-05-19 23:19:23,549 [trainer.py] => ID: 1
2025-05-19 23:19:23,549 [trainer.py] => dataset: cifar224
2025-05-19 23:19:23,549 [trainer.py] => shuffle: True
2025-05-19 23:19:23,549 [trainer.py] => init_cls: 10
2025-05-19 23:19:23,549 [trainer.py] => increment: 10
2025-05-19 23:19:23,549 [trainer.py] => model_name: adapter
2025-05-19 23:19:23,549 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k_adapter
2025-05-19 23:19:23,549 [trainer.py] => device: [device(type='cuda', index=0)]
2025-05-19 23:19:23,549 [trainer.py] => seed: 1993
2025-05-19 23:19:23,549 [trainer.py] => batch_size: 50
2025-05-19 23:19:23,549 [trainer.py] => tuned_epoch: 20
2025-05-19 23:19:23,550 [trainer.py] => body_lr: 0.01
2025-05-19 23:19:23,550 [trainer.py] => head_lr: 0.01
2025-05-19 23:19:23,550 [trainer.py] => weight_decay: 0.0005
2025-05-19 23:19:23,550 [trainer.py] => min_lr: 0.0
2025-05-19 23:19:23,550 [trainer.py] => use_RP: True
2025-05-19 23:19:23,550 [trainer.py] => M: 10000
2025-05-19 23:19:23,550 [trainer.py] => use_input_norm: False
2025-05-19 23:19:23,550 [trainer.py] => meta: True
2025-05-19 23:19:23,550 [trainer.py] => exp_details: FLaSc
2025-05-19 23:19:23,550 [trainer.py] => do_not_save: False
2025-05-19 23:19:23,550 [trainer.py] => seed_path: ./subsets/cifar100/shot1_seed4.txt
2025-05-19 23:19:23,550 [trainer.py] => class_samples_seed: 4
2025-05-19 23:19:23,550 [trainer.py] => shot: 1
2025-05-19 23:19:25,325 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-05-19 23:19:28,133 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-05-19 23:19:29,113 [data_manager.py] => Class Order: [68,56,78,8,23,84,90,65,74,76,40,89,3,92,55,9,26,80,43,38,58,70,77,1,85,19,17,50,28,53,13,81,45,82,6,59,83,16,15,44,91,41,72,60,79,52,20,10,31,54,37,95,14,71,96,98,97,2,64,66,42,22,35,86,24,34,87,21,99,0,88,27,18,94,11,12,47,25,30,46,62,69,36,61,7,63,75,5,32,4,51,48,73,93,39,67,29,49,57,33]
2025-05-19 23:19:29,128 [trainer.py] => Pre-trained network parameters: 86988288
2025-05-19 23:19:30,070 [FLaSc.py] => Starting CIL Task 1
2025-05-19 23:19:30,070 [FLaSc.py] => Learning on classes 0-9
2025-05-19 23:19:30,072 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:19:30,073 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:19:30,073 [FLaSc.py] => len_test data : 1000
2025-05-19 23:19:30,073 [FLaSc.py] => classes learning unique, count: (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:19:30,133 [FLaSc.py] => 86,995,969 total parameters.
2025-05-19 23:19:30,133 [FLaSc.py] => 1,197,313 training parameters.
2025-05-19 23:19:30,134 [FLaSc.py] => Starting PETL training on first task using adapter method
2025-05-19 23:19:30,134 [FLaSc.py] => Training Started with self -supervised loss......
2025-05-19 23:19:30,134 [FLaSc.py] => Weight scale value mse ...... 1.0
2025-05-19 23:21:36,568 [FLaSc.py] => Task 0, Epoch 20/20 => Loss 0.896, Train_accy 0.00, Test_accy 7.40
2025-05-19 23:21:48,187 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:21:48,777 [FLaSc.py] => 87,088,289 total parameters.
2025-05-19 23:21:48,778 [FLaSc.py] => 100,001 training parameters.
2025-05-19 23:21:53,288 [trainer.py] => Group Accuracies after this task: {'00-09': 81.3}
2025-05-19 23:21:53,288 [trainer.py] => Ave Acc curve: [81.3]
2025-05-19 23:21:53,288 [trainer.py] => Ave Inc Acc curve: 81.3
2025-05-19 23:21:53,288 [trainer.py] => Top1 curve: [81.3]
2025-05-19 23:21:53,288 [FLaSc.py] => Starting CIL Task 2
2025-05-19 23:21:53,288 [FLaSc.py] => Learning on classes 10-19
2025-05-19 23:21:53,293 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:21:53,293 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:21:53,293 [FLaSc.py] => len_test data : 2000
2025-05-19 23:21:53,293 [FLaSc.py] => classes learning unique, count: (array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:22:04,396 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:22:05,004 [FLaSc.py] => 87,188,289 total parameters.
2025-05-19 23:22:05,005 [FLaSc.py] => 200,001 training parameters.
2025-05-19 23:22:13,167 [trainer.py] => Group Accuracies after this task: {'00-09': 76.4, '10-19': 73.2}
2025-05-19 23:22:13,167 [trainer.py] => Ave Acc curve: [81.3, 74.8]
2025-05-19 23:22:13,167 [trainer.py] => Ave Inc Acc curve: 78.05
2025-05-19 23:22:13,167 [trainer.py] => Top1 curve: [81.3, 74.8]
2025-05-19 23:22:13,167 [FLaSc.py] => Starting CIL Task 3
2025-05-19 23:22:13,167 [FLaSc.py] => Learning on classes 20-29
2025-05-19 23:22:13,174 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:22:13,174 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:22:13,174 [FLaSc.py] => len_test data : 3000
2025-05-19 23:22:13,174 [FLaSc.py] => classes learning unique, count: (array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:22:24,131 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:22:24,733 [FLaSc.py] => 87,288,289 total parameters.
2025-05-19 23:22:24,734 [FLaSc.py] => 300,001 training parameters.
2025-05-19 23:22:35,916 [trainer.py] => Group Accuracies after this task: {'00-09': 71.9, '10-19': 67.5, '20-29': 81.6}
2025-05-19 23:22:35,916 [trainer.py] => Ave Acc curve: [81.3, 74.8, 73.67]
2025-05-19 23:22:35,916 [trainer.py] => Ave Inc Acc curve: 76.58999999999999
2025-05-19 23:22:35,917 [trainer.py] => Top1 curve: [81.3, 74.8, 73.67]
2025-05-19 23:22:35,917 [FLaSc.py] => Starting CIL Task 4
2025-05-19 23:22:35,917 [FLaSc.py] => Learning on classes 30-39
2025-05-19 23:22:35,927 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:22:35,927 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:22:35,927 [FLaSc.py] => len_test data : 4000
2025-05-19 23:22:35,927 [FLaSc.py] => classes learning unique, count: (array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:22:47,080 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:22:47,683 [FLaSc.py] => 87,388,289 total parameters.
2025-05-19 23:22:47,684 [FLaSc.py] => 400,001 training parameters.
2025-05-19 23:23:01,465 [trainer.py] => Group Accuracies after this task: {'00-09': 68.9, '10-19': 63.3, '20-29': 75.5, '30-39': 58.9}
2025-05-19 23:23:01,465 [trainer.py] => Ave Acc curve: [81.3, 74.8, 73.67, 66.65]
2025-05-19 23:23:01,465 [trainer.py] => Ave Inc Acc curve: 74.10499999999999
2025-05-19 23:23:01,465 [trainer.py] => Top1 curve: [81.3, 74.8, 73.67, 66.65]
2025-05-19 23:23:01,466 [FLaSc.py] => Starting CIL Task 5
2025-05-19 23:23:01,466 [FLaSc.py] => Learning on classes 40-49
2025-05-19 23:23:01,477 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:23:01,477 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:23:01,477 [FLaSc.py] => len_test data : 5000
2025-05-19 23:23:01,477 [FLaSc.py] => classes learning unique, count: (array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:23:12,634 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:23:13,242 [FLaSc.py] => 87,488,289 total parameters.
2025-05-19 23:23:13,243 [FLaSc.py] => 500,001 training parameters.
2025-05-19 23:23:29,399 [trainer.py] => Group Accuracies after this task: {'00-09': 66.5, '10-19': 61.1, '20-29': 71.6, '30-39': 58.2, '40-49': 67.7}
2025-05-19 23:23:29,399 [trainer.py] => Ave Acc curve: [81.3, 74.8, 73.67, 66.65, 65.02]
2025-05-19 23:23:29,399 [trainer.py] => Ave Inc Acc curve: 72.28799999999998
2025-05-19 23:23:29,399 [trainer.py] => Top1 curve: [81.3, 74.8, 73.67, 66.65, 65.02]
2025-05-19 23:23:29,400 [FLaSc.py] => Starting CIL Task 6
2025-05-19 23:23:29,400 [FLaSc.py] => Learning on classes 50-59
2025-05-19 23:23:29,415 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:23:29,415 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:23:29,415 [FLaSc.py] => len_test data : 6000
2025-05-19 23:23:29,416 [FLaSc.py] => classes learning unique, count: (array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:23:40,737 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:23:41,335 [FLaSc.py] => 87,588,289 total parameters.
2025-05-19 23:23:41,336 [FLaSc.py] => 600,001 training parameters.
2025-05-19 23:24:00,257 [trainer.py] => Group Accuracies after this task: {'00-09': 64.5, '10-19': 60.9, '20-29': 71.7, '30-39': 58.4, '40-49': 66.6, '50-59': 57.1}
2025-05-19 23:24:00,257 [trainer.py] => Ave Acc curve: [81.3, 74.8, 73.67, 66.65, 65.02, 63.2]
2025-05-19 23:24:00,258 [trainer.py] => Ave Inc Acc curve: 70.77333333333333
2025-05-19 23:24:00,258 [trainer.py] => Top1 curve: [81.3, 74.8, 73.67, 66.65, 65.02, 63.2]
2025-05-19 23:24:00,258 [FLaSc.py] => Starting CIL Task 7
2025-05-19 23:24:00,258 [FLaSc.py] => Learning on classes 60-69
2025-05-19 23:24:00,275 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:24:00,275 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:24:00,275 [FLaSc.py] => len_test data : 7000
2025-05-19 23:24:00,275 [FLaSc.py] => classes learning unique, count: (array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:24:11,452 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:24:12,049 [FLaSc.py] => 87,688,289 total parameters.
2025-05-19 23:24:12,050 [FLaSc.py] => 700,001 training parameters.
2025-05-19 23:24:33,590 [trainer.py] => Group Accuracies after this task: {'00-09': 62.0, '10-19': 59.4, '20-29': 70.7, '30-39': 55.6, '40-49': 66.4, '50-59': 55.2, '60-69': 65.9}
2025-05-19 23:24:33,590 [trainer.py] => Ave Acc curve: [81.3, 74.8, 73.67, 66.65, 65.02, 63.2, 62.17]
2025-05-19 23:24:33,590 [trainer.py] => Ave Inc Acc curve: 69.5442857142857
2025-05-19 23:24:33,590 [trainer.py] => Top1 curve: [81.3, 74.8, 73.67, 66.65, 65.02, 63.2, 62.17]
2025-05-19 23:24:33,591 [FLaSc.py] => Starting CIL Task 8
2025-05-19 23:24:33,591 [FLaSc.py] => Learning on classes 70-79
2025-05-19 23:24:33,608 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:24:33,608 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:24:33,608 [FLaSc.py] => len_test data : 8000
2025-05-19 23:24:33,609 [FLaSc.py] => classes learning unique, count: (array([70, 71, 72, 73, 74, 75, 76, 77, 78, 79]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:24:44,733 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:24:45,343 [FLaSc.py] => 87,788,289 total parameters.
2025-05-19 23:24:45,343 [FLaSc.py] => 800,001 training parameters.
2025-05-19 23:25:09,359 [trainer.py] => Group Accuracies after this task: {'00-09': 59.5, '10-19': 58.5, '20-29': 70.3, '30-39': 55.3, '40-49': 62.1, '50-59': 50.0, '60-69': 61.3, '70-79': 54.1}
2025-05-19 23:25:09,359 [trainer.py] => Ave Acc curve: [81.3, 74.8, 73.67, 66.65, 65.02, 63.2, 62.17, 58.89]
2025-05-19 23:25:09,359 [trainer.py] => Ave Inc Acc curve: 68.21249999999999
2025-05-19 23:25:09,359 [trainer.py] => Top1 curve: [81.3, 74.8, 73.67, 66.65, 65.02, 63.2, 62.17, 58.89]
2025-05-19 23:25:09,360 [FLaSc.py] => Starting CIL Task 9
2025-05-19 23:25:09,360 [FLaSc.py] => Learning on classes 80-89
2025-05-19 23:25:09,379 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:25:09,379 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:25:09,379 [FLaSc.py] => len_test data : 9000
2025-05-19 23:25:09,379 [FLaSc.py] => classes learning unique, count: (array([80, 81, 82, 83, 84, 85, 86, 87, 88, 89]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:25:20,564 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:25:21,166 [FLaSc.py] => 87,888,289 total parameters.
2025-05-19 23:25:21,167 [FLaSc.py] => 900,001 training parameters.
2025-05-19 23:25:47,892 [trainer.py] => Group Accuracies after this task: {'00-09': 59.5, '10-19': 57.8, '20-29': 68.0, '30-39': 55.1, '40-49': 59.8, '50-59': 49.5, '60-69': 59.5, '70-79': 53.6, '80-89': 60.4}
2025-05-19 23:25:47,892 [trainer.py] => Ave Acc curve: [81.3, 74.8, 73.67, 66.65, 65.02, 63.2, 62.17, 58.89, 58.13]
2025-05-19 23:25:47,892 [trainer.py] => Ave Inc Acc curve: 67.09222222222222
2025-05-19 23:25:47,892 [trainer.py] => Top1 curve: [81.3, 74.8, 73.67, 66.65, 65.02, 63.2, 62.17, 58.89, 58.13]
2025-05-19 23:25:47,893 [FLaSc.py] => Starting CIL Task 10
2025-05-19 23:25:47,893 [FLaSc.py] => Learning on classes 90-99
2025-05-19 23:25:47,915 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:25:47,915 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:25:47,915 [FLaSc.py] => len_test data : 10000
2025-05-19 23:25:47,915 [FLaSc.py] => classes learning unique, count: (array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:25:59,104 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:25:59,708 [FLaSc.py] => 87,988,289 total parameters.
2025-05-19 23:25:59,708 [FLaSc.py] => 1,000,001 training parameters.
2025-05-19 23:26:29,114 [trainer.py] => Group Accuracies after this task: {'00-09': 57.4, '10-19': 57.5, '20-29': 65.4, '30-39': 54.0, '40-49': 58.7, '50-59': 49.0, '60-69': 58.8, '70-79': 51.3, '80-89': 58.2, '90-99': 65.0}
2025-05-19 23:26:29,114 [trainer.py] => Ave Acc curve: [81.3, 74.8, 73.67, 66.65, 65.02, 63.2, 62.17, 58.89, 58.13, 57.53]
2025-05-19 23:26:29,114 [trainer.py] => Ave Inc Acc curve: 66.136
2025-05-19 23:26:29,114 [trainer.py] => Top1 curve: [81.3, 74.8, 73.67, 66.65, 65.02, 63.2, 62.17, 58.89, 58.13, 57.53]
2025-05-19 23:26:29,114 [trainer.py] => Finishing run
2025-05-19 23:26:29,114 [trainer.py] => 
