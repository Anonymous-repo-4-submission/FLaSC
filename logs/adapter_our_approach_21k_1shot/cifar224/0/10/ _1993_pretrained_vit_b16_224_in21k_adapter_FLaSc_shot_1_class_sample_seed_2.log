2025-05-19 23:05:13,693 [trainer.py] => Starting new run
2025-05-19 23:05:13,694 [trainer.py] => ID: 1
2025-05-19 23:05:13,694 [trainer.py] => dataset: cifar224
2025-05-19 23:05:13,694 [trainer.py] => shuffle: True
2025-05-19 23:05:13,694 [trainer.py] => init_cls: 10
2025-05-19 23:05:13,694 [trainer.py] => increment: 10
2025-05-19 23:05:13,694 [trainer.py] => model_name: adapter
2025-05-19 23:05:13,694 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k_adapter
2025-05-19 23:05:13,694 [trainer.py] => device: [device(type='cuda', index=0)]
2025-05-19 23:05:13,694 [trainer.py] => seed: 1993
2025-05-19 23:05:13,694 [trainer.py] => batch_size: 50
2025-05-19 23:05:13,694 [trainer.py] => tuned_epoch: 20
2025-05-19 23:05:13,694 [trainer.py] => body_lr: 0.01
2025-05-19 23:05:13,694 [trainer.py] => head_lr: 0.01
2025-05-19 23:05:13,694 [trainer.py] => weight_decay: 0.0005
2025-05-19 23:05:13,694 [trainer.py] => min_lr: 0.0
2025-05-19 23:05:13,694 [trainer.py] => use_RP: True
2025-05-19 23:05:13,694 [trainer.py] => M: 10000
2025-05-19 23:05:13,694 [trainer.py] => use_input_norm: False
2025-05-19 23:05:13,694 [trainer.py] => meta: True
2025-05-19 23:05:13,694 [trainer.py] => exp_details: FLaSc
2025-05-19 23:05:13,694 [trainer.py] => do_not_save: False
2025-05-19 23:05:13,694 [trainer.py] => seed_path: ./subsets/cifar100/shot1_seed2.txt
2025-05-19 23:05:13,694 [trainer.py] => class_samples_seed: 2
2025-05-19 23:05:13,694 [trainer.py] => shot: 1
2025-05-19 23:05:15,347 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2025-05-19 23:05:15,668 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-05-19 23:05:16,637 [data_manager.py] => Class Order: [68,56,78,8,23,84,90,65,74,76,40,89,3,92,55,9,26,80,43,38,58,70,77,1,85,19,17,50,28,53,13,81,45,82,6,59,83,16,15,44,91,41,72,60,79,52,20,10,31,54,37,95,14,71,96,98,97,2,64,66,42,22,35,86,24,34,87,21,99,0,88,27,18,94,11,12,47,25,30,46,62,69,36,61,7,63,75,5,32,4,51,48,73,93,39,67,29,49,57,33]
2025-05-19 23:05:16,652 [trainer.py] => Pre-trained network parameters: 86988288
2025-05-19 23:05:17,585 [FLaSc.py] => Starting CIL Task 1
2025-05-19 23:05:17,585 [FLaSc.py] => Learning on classes 0-9
2025-05-19 23:05:17,587 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:05:17,587 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:05:17,587 [FLaSc.py] => len_test data : 1000
2025-05-19 23:05:17,587 [FLaSc.py] => classes learning unique, count: (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:05:17,647 [FLaSc.py] => 86,995,969 total parameters.
2025-05-19 23:05:17,647 [FLaSc.py] => 1,197,313 training parameters.
2025-05-19 23:05:17,648 [FLaSc.py] => Starting PETL training on first task using adapter method
2025-05-19 23:05:17,648 [FLaSc.py] => Training Started with self -supervised loss......
2025-05-19 23:05:17,648 [FLaSc.py] => Weight scale value mse ...... 1.0
2025-05-19 23:07:23,705 [FLaSc.py] => Task 0, Epoch 20/20 => Loss 0.888, Train_accy 0.00, Test_accy 7.50
2025-05-19 23:07:35,263 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:07:35,862 [FLaSc.py] => 87,088,289 total parameters.
2025-05-19 23:07:35,862 [FLaSc.py] => 100,001 training parameters.
2025-05-19 23:07:40,410 [trainer.py] => Group Accuracies after this task: {'00-09': 81.9}
2025-05-19 23:07:40,411 [trainer.py] => Ave Acc curve: [81.9]
2025-05-19 23:07:40,411 [trainer.py] => Ave Inc Acc curve: 81.9
2025-05-19 23:07:40,411 [trainer.py] => Top1 curve: [81.9]
2025-05-19 23:07:40,411 [FLaSc.py] => Starting CIL Task 2
2025-05-19 23:07:40,411 [FLaSc.py] => Learning on classes 10-19
2025-05-19 23:07:40,418 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:07:40,418 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:07:40,418 [FLaSc.py] => len_test data : 2000
2025-05-19 23:07:40,419 [FLaSc.py] => classes learning unique, count: (array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:07:51,370 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:07:51,965 [FLaSc.py] => 87,188,289 total parameters.
2025-05-19 23:07:51,966 [FLaSc.py] => 200,001 training parameters.
2025-05-19 23:08:00,051 [trainer.py] => Group Accuracies after this task: {'00-09': 76.3, '10-19': 75.6}
2025-05-19 23:08:00,051 [trainer.py] => Ave Acc curve: [81.9, 75.95]
2025-05-19 23:08:00,051 [trainer.py] => Ave Inc Acc curve: 78.92500000000001
2025-05-19 23:08:00,051 [trainer.py] => Top1 curve: [81.9, 75.95]
2025-05-19 23:08:00,052 [FLaSc.py] => Starting CIL Task 3
2025-05-19 23:08:00,052 [FLaSc.py] => Learning on classes 20-29
2025-05-19 23:08:00,058 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:08:00,058 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:08:00,058 [FLaSc.py] => len_test data : 3000
2025-05-19 23:08:00,059 [FLaSc.py] => classes learning unique, count: (array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:08:10,986 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:08:11,581 [FLaSc.py] => 87,288,289 total parameters.
2025-05-19 23:08:11,582 [FLaSc.py] => 300,001 training parameters.
2025-05-19 23:08:22,768 [trainer.py] => Group Accuracies after this task: {'00-09': 72.0, '10-19': 67.9, '20-29': 73.2}
2025-05-19 23:08:22,768 [trainer.py] => Ave Acc curve: [81.9, 75.95, 71.03]
2025-05-19 23:08:22,768 [trainer.py] => Ave Inc Acc curve: 76.29333333333334
2025-05-19 23:08:22,768 [trainer.py] => Top1 curve: [81.9, 75.95, 71.03]
2025-05-19 23:08:22,769 [FLaSc.py] => Starting CIL Task 4
2025-05-19 23:08:22,769 [FLaSc.py] => Learning on classes 30-39
2025-05-19 23:08:22,780 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:08:22,780 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:08:22,780 [FLaSc.py] => len_test data : 4000
2025-05-19 23:08:22,780 [FLaSc.py] => classes learning unique, count: (array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:08:33,862 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:08:34,470 [FLaSc.py] => 87,388,289 total parameters.
2025-05-19 23:08:34,471 [FLaSc.py] => 400,001 training parameters.
2025-05-19 23:08:48,115 [trainer.py] => Group Accuracies after this task: {'00-09': 65.0, '10-19': 62.7, '20-29': 71.9, '30-39': 63.3}
2025-05-19 23:08:48,115 [trainer.py] => Ave Acc curve: [81.9, 75.95, 71.03, 65.73]
2025-05-19 23:08:48,115 [trainer.py] => Ave Inc Acc curve: 73.6525
2025-05-19 23:08:48,115 [trainer.py] => Top1 curve: [81.9, 75.95, 71.03, 65.72]
2025-05-19 23:08:48,116 [FLaSc.py] => Starting CIL Task 5
2025-05-19 23:08:48,116 [FLaSc.py] => Learning on classes 40-49
2025-05-19 23:08:48,127 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:08:48,127 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:08:48,127 [FLaSc.py] => len_test data : 5000
2025-05-19 23:08:48,127 [FLaSc.py] => classes learning unique, count: (array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:08:59,279 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:08:59,879 [FLaSc.py] => 87,488,289 total parameters.
2025-05-19 23:08:59,880 [FLaSc.py] => 500,001 training parameters.
2025-05-19 23:09:16,181 [trainer.py] => Group Accuracies after this task: {'00-09': 64.6, '10-19': 60.0, '20-29': 71.0, '30-39': 57.2, '40-49': 63.7}
2025-05-19 23:09:16,181 [trainer.py] => Ave Acc curve: [81.9, 75.95, 71.03, 65.73, 63.3]
2025-05-19 23:09:16,181 [trainer.py] => Ave Inc Acc curve: 71.58200000000001
2025-05-19 23:09:16,181 [trainer.py] => Top1 curve: [81.9, 75.95, 71.03, 65.72, 63.3]
2025-05-19 23:09:16,182 [FLaSc.py] => Starting CIL Task 6
2025-05-19 23:09:16,182 [FLaSc.py] => Learning on classes 50-59
2025-05-19 23:09:16,196 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:09:16,197 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:09:16,197 [FLaSc.py] => len_test data : 6000
2025-05-19 23:09:16,197 [FLaSc.py] => classes learning unique, count: (array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:09:27,278 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:09:27,880 [FLaSc.py] => 87,588,289 total parameters.
2025-05-19 23:09:27,881 [FLaSc.py] => 600,001 training parameters.
2025-05-19 23:09:46,704 [trainer.py] => Group Accuracies after this task: {'00-09': 62.4, '10-19': 60.1, '20-29': 68.9, '30-39': 56.1, '40-49': 62.7, '50-59': 56.6}
2025-05-19 23:09:46,705 [trainer.py] => Ave Acc curve: [81.9, 75.95, 71.03, 65.73, 63.3, 61.13]
2025-05-19 23:09:46,705 [trainer.py] => Ave Inc Acc curve: 69.84
2025-05-19 23:09:46,705 [trainer.py] => Top1 curve: [81.9, 75.95, 71.03, 65.72, 63.3, 61.13]
2025-05-19 23:09:46,706 [FLaSc.py] => Starting CIL Task 7
2025-05-19 23:09:46,706 [FLaSc.py] => Learning on classes 60-69
2025-05-19 23:09:46,722 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:09:46,722 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:09:46,722 [FLaSc.py] => len_test data : 7000
2025-05-19 23:09:46,722 [FLaSc.py] => classes learning unique, count: (array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:09:57,827 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:09:58,426 [FLaSc.py] => 87,688,289 total parameters.
2025-05-19 23:09:58,427 [FLaSc.py] => 700,001 training parameters.
2025-05-19 23:10:19,919 [trainer.py] => Group Accuracies after this task: {'00-09': 60.7, '10-19': 58.7, '20-29': 68.2, '30-39': 55.2, '40-49': 62.7, '50-59': 56.4, '60-69': 58.6}
2025-05-19 23:10:19,920 [trainer.py] => Ave Acc curve: [81.9, 75.95, 71.03, 65.73, 63.3, 61.13, 60.07]
2025-05-19 23:10:19,920 [trainer.py] => Ave Inc Acc curve: 68.44428571428571
2025-05-19 23:10:19,920 [trainer.py] => Top1 curve: [81.9, 75.95, 71.03, 65.72, 63.3, 61.13, 60.07]
2025-05-19 23:10:19,920 [FLaSc.py] => Starting CIL Task 8
2025-05-19 23:10:19,921 [FLaSc.py] => Learning on classes 70-79
2025-05-19 23:10:19,939 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:10:19,939 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:10:19,939 [FLaSc.py] => len_test data : 8000
2025-05-19 23:10:19,940 [FLaSc.py] => classes learning unique, count: (array([70, 71, 72, 73, 74, 75, 76, 77, 78, 79]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:10:31,101 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:10:31,705 [FLaSc.py] => 87,788,289 total parameters.
2025-05-19 23:10:31,706 [FLaSc.py] => 800,001 training parameters.
2025-05-19 23:10:55,747 [trainer.py] => Group Accuracies after this task: {'00-09': 59.2, '10-19': 57.8, '20-29': 67.3, '30-39': 54.6, '40-49': 60.5, '50-59': 51.3, '60-69': 56.9, '70-79': 53.3}
2025-05-19 23:10:55,747 [trainer.py] => Ave Acc curve: [81.9, 75.95, 71.03, 65.73, 63.3, 61.13, 60.07, 57.61]
2025-05-19 23:10:55,747 [trainer.py] => Ave Inc Acc curve: 67.09
2025-05-19 23:10:55,747 [trainer.py] => Top1 curve: [81.9, 75.95, 71.03, 65.72, 63.3, 61.13, 60.07, 57.61]
2025-05-19 23:10:55,748 [FLaSc.py] => Starting CIL Task 9
2025-05-19 23:10:55,748 [FLaSc.py] => Learning on classes 80-89
2025-05-19 23:10:55,768 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:10:55,768 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:10:55,768 [FLaSc.py] => len_test data : 9000
2025-05-19 23:10:55,768 [FLaSc.py] => classes learning unique, count: (array([80, 81, 82, 83, 84, 85, 86, 87, 88, 89]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:11:07,115 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:11:07,720 [FLaSc.py] => 87,888,289 total parameters.
2025-05-19 23:11:07,720 [FLaSc.py] => 900,001 training parameters.
2025-05-19 23:11:34,360 [trainer.py] => Group Accuracies after this task: {'00-09': 59.4, '10-19': 53.2, '20-29': 65.8, '30-39': 54.0, '40-49': 60.3, '50-59': 51.2, '60-69': 56.0, '70-79': 52.6, '80-89': 54.1}
2025-05-19 23:11:34,360 [trainer.py] => Ave Acc curve: [81.9, 75.95, 71.03, 65.73, 63.3, 61.13, 60.07, 57.61, 56.29]
2025-05-19 23:11:34,360 [trainer.py] => Ave Inc Acc curve: 65.89
2025-05-19 23:11:34,360 [trainer.py] => Top1 curve: [81.9, 75.95, 71.03, 65.72, 63.3, 61.13, 60.07, 57.61, 56.29]
2025-05-19 23:11:34,361 [FLaSc.py] => Starting CIL Task 10
2025-05-19 23:11:34,361 [FLaSc.py] => Learning on classes 90-99
2025-05-19 23:11:34,382 [FLaSc.py] => len_supervised data : 10
2025-05-19 23:11:34,382 [FLaSc.py] => len supervised data for G inc calculation : 10
2025-05-19 23:11:34,382 [FLaSc.py] => len_test data : 10000
2025-05-19 23:11:34,382 [FLaSc.py] => classes learning unique, count: (array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))
2025-05-19 23:11:45,454 [FLaSc.py] => Optimal lambda for shot 1: 100000000.0
2025-05-19 23:11:46,054 [FLaSc.py] => 87,988,289 total parameters.
2025-05-19 23:11:46,055 [FLaSc.py] => 1,000,001 training parameters.
2025-05-19 23:12:15,418 [trainer.py] => Group Accuracies after this task: {'00-09': 58.2, '10-19': 52.8, '20-29': 64.8, '30-39': 53.5, '40-49': 59.0, '50-59': 50.5, '60-69': 54.1, '70-79': 52.6, '80-89': 53.9, '90-99': 48.4}
2025-05-19 23:12:15,419 [trainer.py] => Ave Acc curve: [81.9, 75.95, 71.03, 65.73, 63.3, 61.13, 60.07, 57.61, 56.29, 54.78]
2025-05-19 23:12:15,419 [trainer.py] => Ave Inc Acc curve: 64.779
2025-05-19 23:12:15,419 [trainer.py] => Top1 curve: [81.9, 75.95, 71.03, 65.72, 63.3, 61.13, 60.07, 57.61, 56.29, 54.78]
2025-05-19 23:12:15,419 [trainer.py] => Finishing run
2025-05-19 23:12:15,419 [trainer.py] => 
